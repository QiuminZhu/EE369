{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“0.62.ipynb”的副本",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSqvoVdcigbX",
        "colab_type": "text"
      },
      "source": [
        "加载google drive目录 \n",
        "mylib需在目录中自行添加上传"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1tuA4gHo2ZQ",
        "colab_type": "code",
        "outputId": "79556120-5d08-42f0-c619-74bd6ab0b084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruLdEQJWivmM",
        "colab_type": "text"
      },
      "source": [
        "主程序"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgjSX_t6firm",
        "colab_type": "code",
        "outputId": "5d832eeb-3f3f-42a5-bce3-2645ad93ed73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from collections.abc import Sequence\n",
        "import random\n",
        "from pandas import DataFrame\n",
        "\n",
        "from mylib.utils.misc import rotation, reflection, crop, random_center, _triple\n",
        "filepath=\"/content/drive/My Drive/cnn/train_val.csv\"\n",
        "result=pd.read_csv('/content/drive/My Drive/cnn/sampleSubmission.csv')\n",
        "df=pd.read_csv(filepath,header=0,engine=\"python\")\n",
        "class Transform:\n",
        "    '''The online data augmentation, including:\n",
        "    1) random move the center by `move`\n",
        "    2) rotation 90 degrees increments\n",
        "    3) reflection in any axis\n",
        "    '''\n",
        "\n",
        "    def __init__(self, size, move):\n",
        "        self.size = _triple(size)\n",
        "        self.move = move\n",
        "\n",
        "    def __call__(self, arr, aux=None):\n",
        "        shape = arr.shape\n",
        "        if self.move is not None:\n",
        "            center = random_center(shape, self.move)\n",
        "            arr_ret = crop(arr, center, self.size)\n",
        "            angle = np.random.randint(4, size=3)\n",
        "            arr_ret = rotation(arr_ret, angle=angle)\n",
        "            axis = np.random.randint(4) - 1\n",
        "            arr_ret = reflection(arr_ret, axis=axis)\n",
        "            arr_ret = np.expand_dims(arr_ret, axis=-1)\n",
        "            if aux is not None:\n",
        "                aux_ret = crop(aux, center, self.size)\n",
        "                aux_ret = rotation(aux_ret, angle=angle)\n",
        "                aux_ret = reflection(aux_ret, axis=axis)\n",
        "                aux_ret = np.expand_dims(aux_ret, axis=-1)\n",
        "                return arr_ret, aux_ret\n",
        "            return arr_ret\n",
        "        else:\n",
        "            center = np.array(shape) // 2\n",
        "            arr_ret = crop(arr, center, self.size)\n",
        "            arr_ret = np.expand_dims(arr_ret, axis=-1)\n",
        "            if aux is not None:\n",
        "                aux_ret = crop(aux, center, self.size)\n",
        "                aux_ret = np.expand_dims(aux_ret, axis=-1)\n",
        "                return arr_ret, aux_ret\n",
        "            return arr_ret\n",
        "\n",
        "class ClfDataset(Sequence):\n",
        "    def __init__(self, crop_size=32, move=None):\n",
        "        self.transform = Transform(crop_size, move)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        name = df.loc[item, 'name']\n",
        "        with np.load(os.path.join('/content/drive/My Drive/cnn/train_val', '%s.npz' % name)) as npz:\n",
        "            voxel, seg = self.transform(npz['voxel'], npz['seg'])\n",
        "        voxel=voxel*seg\n",
        "        label = df.loc[item, 'lable']\n",
        "        return voxel, (label,seg)\n",
        "\n",
        "    def __len__(self):\n",
        "        return df._len_()\n",
        "\n",
        "    @staticmethod\n",
        "    def _collate_fn(data):\n",
        "        xs = []\n",
        "        ys = []\n",
        "        segs = []\n",
        "        for x, y in data:\n",
        "            xs.append(x)\n",
        "            ys.append(y[0])\n",
        "            segs.append(y[1])\n",
        "        return np.array(xs), {\"clf\": np.array(ys), \"seg\": np.array(segs)}\n",
        "\n",
        "class ClfDataset_test(Sequence):\n",
        "    def __init__(self, crop_size=32, move=None):\n",
        "        self.transform = Transform(crop_size,move)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        name = result.loc[item, 'name']\n",
        "        with np.load(os.path.join('/content/drive/My Drive/cnn/test', '%s.npz' % name)) as npz:\n",
        "            voxel, seg = self.transform(npz['voxel'], npz['seg'])\n",
        "        voxel=voxel*seg\n",
        "        return voxel\n",
        "\n",
        "    def __len__(self):\n",
        "           \n",
        "        return df.__len__()\n",
        "\n",
        "    @staticmethod\n",
        "    def _collate_fn(data):\n",
        "        xs = []\n",
        "        for x in data:\n",
        "            xs.append(x)\n",
        "        return np.array(xs)\n",
        "\n",
        "def get_loader_train(dataset, batch_size):\n",
        "    total_size = 415\n",
        "    print('Size', total_size)\n",
        "    index_generator = shuffle_iterator(range(total_size))\n",
        "    while True:\n",
        "        data = []\n",
        "        for _ in range(batch_size):\n",
        "            idx = next(index_generator)\n",
        "            data.append(dataset[idx])\n",
        "        yield dataset._collate_fn(data)\n",
        "\n",
        "def get_loader_val(dataset, batch_size):\n",
        "    total_size = 50\n",
        "    print('Size', total_size)\n",
        "    index_generator = shuffle_iterator(range(total_size))\n",
        "    while True:\n",
        "        data = []\n",
        "        for _ in range(batch_size):\n",
        "            idx = next(index_generator)\n",
        "            data.append(dataset[idx+415])\n",
        "        yield dataset._collate_fn(data)\n",
        "\n",
        "def get_loader_test(dataset, batch_size):\n",
        "    total_size = 117\n",
        "    print('Size', total_size)\n",
        "    #index_generator = shuffle_iterator(range(total_size))\n",
        "    while True:\n",
        "        data = []\n",
        "        for i in range(batch_size):\n",
        "            #idx = next(index_generator)\n",
        "            idx=i\n",
        "            data.append(dataset[idx])\n",
        "        yield dataset._collate_fn(data)\n",
        "\n",
        "def shuffle_iterator(iterator):\n",
        "    # iterator should have limited size\n",
        "    index = list(iterator)\n",
        "    total_size = len(index)\n",
        "    i = 0\n",
        "    random.shuffle(index)\n",
        "    while True:\n",
        "        yield index[i]\n",
        "        i += 1\n",
        "        if i >= total_size:\n",
        "            i = 0\n",
        "            random.shuffle(index)\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "dataset = ClfDataset(crop_size=32)\n",
        "test_dataset = ClfDataset_test(crop_size=32)\n",
        "train_loader = get_loader_train(dataset, batch_size=40)\n",
        "val_loader = get_loader_val(dataset, batch_size=10)\n",
        "test_loader = get_loader_test(test_dataset, batch_size=117)\n",
        "crop_size=[32, 32, 32]\n",
        "random_move=3\n",
        "learning_rate=1.e-4\n",
        "segmentation_task_ratio=0.2\n",
        "weight_decay=0.\n",
        "save_folder='test'\n",
        "epochs=100\n",
        "\n",
        "\n",
        "from keras.layers import (Conv3D, BatchNormalization, AveragePooling3D, concatenate, Lambda, SpatialDropout3D,\n",
        "                          Activation, Input, GlobalAvgPool3D, Dense, Conv3DTranspose, add)\n",
        "from keras.regularizers import l2 as l2_penalty\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "PARAMS = {\n",
        "    'activation': lambda: Activation('relu'),  # the activation functions\n",
        "    'bn_scale': True,  # whether to use the scale function in BN\n",
        "    'weight_decay': 0.,  # l2 weight decay\n",
        "    'kernel_initializer': 'he_uniform',  # initialization\n",
        "    'first_scale': lambda x: x / 128. - 1.,  # the first pre-processing function\n",
        "    'dhw': [32, 32, 32],  # the input shape\n",
        "    'k': 16,  # the `growth rate` in DenseNet\n",
        "    'bottleneck': 4,  # the `bottleneck` in DenseNet\n",
        "    'compression': 2,  # the `compression` in DenseNet\n",
        "    'first_layer': 32,  # the channel of the first layer\n",
        "    'down_structure': [2, 2, 2],  # the down-sample structure\n",
        "    'output_size': 1,  # the output number of the classification head\n",
        "    'dropout_rate': None  # whether to use dropout, and how much to use\n",
        "}\n",
        "\n",
        "\n",
        "def _conv_block(x, filters):\n",
        "    bn_scale = PARAMS['bn_scale']\n",
        "    activation = PARAMS['activation']\n",
        "    kernel_initializer = PARAMS['kernel_initializer']\n",
        "    weight_decay = PARAMS['weight_decay']\n",
        "    bottleneck = PARAMS['bottleneck']\n",
        "    dropout_rate = PARAMS['dropout_rate']\n",
        "\n",
        "    x = BatchNormalization(scale=bn_scale, axis=-1)(x)\n",
        "    x = activation()(x)\n",
        "    x = Conv3D(filters * bottleneck, kernel_size=(1, 1, 1), padding='same', use_bias=False,\n",
        "               kernel_initializer=kernel_initializer,\n",
        "               kernel_regularizer=l2_penalty(weight_decay))(x)\n",
        "    if dropout_rate is not None:\n",
        "        x = SpatialDropout3D(dropout_rate)(x)\n",
        "    x = BatchNormalization(scale=bn_scale, axis=-1)(x)\n",
        "    x = activation()(x)\n",
        "    x = Conv3D(filters, kernel_size=(3, 3, 3), padding='same', use_bias=True,\n",
        "               kernel_initializer=kernel_initializer,\n",
        "               kernel_regularizer=l2_penalty(weight_decay))(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def _dense_block(x, n):\n",
        "    k = PARAMS['k']\n",
        "\n",
        "    for _ in range(n):\n",
        "        conv = _conv_block(x, k)\n",
        "        x = concatenate([conv, x], axis=-1)\n",
        "    return x\n",
        "\n",
        "\n",
        "def _transmit_block(x, is_last):\n",
        "    bn_scale = PARAMS['bn_scale']\n",
        "    activation = PARAMS['activation']\n",
        "    kernel_initializer = PARAMS['kernel_initializer']\n",
        "    weight_decay = PARAMS['weight_decay']\n",
        "    compression = PARAMS['compression']\n",
        "\n",
        "    x = BatchNormalization(scale=bn_scale, axis=-1)(x)\n",
        "    x = activation()(x)\n",
        "    if is_last:\n",
        "        x = GlobalAvgPool3D()(x)\n",
        "    else:\n",
        "        *_, f = x.get_shape().as_list()\n",
        "        x = Conv3D(f // compression, kernel_size=(1, 1, 1), padding='same', use_bias=True,\n",
        "                   kernel_initializer=kernel_initializer,\n",
        "                   kernel_regularizer=l2_penalty(weight_decay))(x)\n",
        "        x = AveragePooling3D((2, 2, 2), padding='valid')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_model(weights=None, verbose=True, **kwargs):\n",
        "    for k, v in kwargs.items():\n",
        "        assert k in PARAMS\n",
        "        PARAMS[k] = v\n",
        "    if verbose:\n",
        "        print(\"Model hyper-parameters:\", PARAMS)\n",
        "\n",
        "    dhw = PARAMS['dhw']\n",
        "    first_scale = PARAMS['first_scale']\n",
        "    first_layer = PARAMS['first_layer']\n",
        "    kernel_initializer = PARAMS['kernel_initializer']\n",
        "    weight_decay = PARAMS['weight_decay']\n",
        "    down_structure = PARAMS['down_structure']\n",
        "    output_size = PARAMS['output_size']\n",
        "\n",
        "    shape = dhw + [1]\n",
        "\n",
        "    inputs = Input(shape=shape)\n",
        "\n",
        "    if first_scale is not None:\n",
        "        scaled = Lambda(first_scale)(inputs)\n",
        "    else:\n",
        "        scaled = inputs\n",
        "    conv = Conv3D(first_layer, kernel_size=(3, 3, 3), padding='same', use_bias=True,\n",
        "                  kernel_initializer=kernel_initializer,\n",
        "                  kernel_regularizer=l2_penalty(weight_decay))(scaled)\n",
        "\n",
        "    downsample_times = len(down_structure)\n",
        "    top_down = []\n",
        "    for l, n in enumerate(down_structure):\n",
        "        db = _dense_block(conv, n)\n",
        "        top_down.append(db)\n",
        "        conv = _transmit_block(db, l == downsample_times - 1)\n",
        "\n",
        "    feat = top_down[-1]\n",
        "    for top_feat in reversed(top_down[:-1]):\n",
        "        *_, f = top_feat.get_shape().as_list()\n",
        "        deconv = Conv3DTranspose(filters=f, kernel_size=2, strides=2, use_bias=True,\n",
        "                                 kernel_initializer=kernel_initializer,\n",
        "                                 kernel_regularizer=l2_penalty(weight_decay))(feat)\n",
        "        feat = add([top_feat, deconv])\n",
        "    seg_head = Conv3D(1, kernel_size=(1, 1, 1), padding='same',\n",
        "                      activation='sigmoid', use_bias=True,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=l2_penalty(weight_decay),\n",
        "                      name='seg')(feat)\n",
        "\n",
        "    if output_size == 1:\n",
        "        last_activation = 'sigmoid'\n",
        "    else:\n",
        "        last_activation = 'softmax'\n",
        "\n",
        "    clf_head = Dense(output_size, activation=last_activation,\n",
        "                     kernel_regularizer=l2_penalty(weight_decay),\n",
        "                     kernel_initializer=kernel_initializer,\n",
        "                     name='clf')(conv)\n",
        "\n",
        "    model = Model(inputs, [clf_head, seg_head])\n",
        "    if verbose:\n",
        "        model.summary()\n",
        "\n",
        "    if weights is not None:\n",
        "        model.load_weights(weights)\n",
        "    return model\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "class DiceLoss:\n",
        "    def __init__(self, beta=1., smooth=1.):\n",
        "        self.__name__ = 'dice_loss_' + str(int(beta * 100))\n",
        "        self.beta = beta  # the more beta, the more recall\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def __call__(self, y_true, y_pred):\n",
        "        bb = self.beta * self.beta\n",
        "        y_true_f = K.batch_flatten(y_true)\n",
        "        y_pred_f = K.batch_flatten(y_pred)\n",
        "        intersection = K.sum(y_true_f * y_pred_f, axis=-1)\n",
        "        weighted_union = bb * K.sum(y_true_f, axis=-1) + \\\n",
        "                         K.sum(y_pred_f, axis=-1)\n",
        "        score = -((1 + bb) * intersection + self.smooth) / \\\n",
        "                (weighted_union + self.smooth)\n",
        "        return score\n",
        "\n",
        "from mylib.model import metrics\n",
        "\n",
        "model = get_model('/content/tmp/test/best.h5')\n",
        "model.compile(optimizer=Adam(lr=learning_rate),\n",
        "              loss={\"clf\": 'binary_crossentropy',\n",
        "                    \"seg\": DiceLoss()},\n",
        "              metrics={'clf': ['accuracy',metrics.auc],'seg': 'accuracy'},\n",
        "              loss_weights={\"clf\": 1., \"seg\": .2})\n",
        "    \n",
        "#checkpointer = ModelCheckpoint(filepath='tmp/%s/weights.{epoch:02d}.h5' % save_folder, verbose=1,\n",
        "#                                   period=1, save_weights_only=True)\n",
        "#best_keeper = ModelCheckpoint(filepath='tmp/%s/best.h5' % save_folder, verbose=1, save_weights_only=True,\n",
        "#                                  monitor='val_clf_acc', save_best_only=True, period=1, mode='max')\n",
        "#csv_logger = CSVLogger('tmp/%s/training.csv' % save_folder)\n",
        "#tensorboard = TensorBoard(log_dir='tmp/%s/logs/' % save_folder)\n",
        "#early_stopping = EarlyStopping(monitor='val_clf_acc', min_delta=0, mode='max',\n",
        "#                                   patience=40, verbose=1)\n",
        "#lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.334, patience=10,\n",
        "#                                   verbose=1, mode='min', epsilon=1.e-5, cooldown=2, min_lr=0)\n",
        "#model.fit_generator(generator=train_loader, steps_per_epoch=20, max_queue_size=500, workers=1,\n",
        "#                        validation_data=val_loader, epochs=epochs, validation_steps=15,\n",
        "#                        callbacks=[checkpointer, early_stopping, best_keeper, lr_reducer, csv_logger, tensorboard])\n",
        "\n",
        "\n",
        "test_data=next(test_loader)\n",
        "print(test_data.shape)\n",
        "b=model.predict(test_data)\n",
        "result['Score']=b[0]\n",
        "save=pd.DataFrame(data=result)\n",
        "save.to_csv('result.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model hyper-parameters: {'activation': <function <lambda> at 0x7f8d551aa378>, 'bn_scale': True, 'weight_decay': 0.0, 'kernel_initializer': 'he_uniform', 'first_scale': <function <lambda> at 0x7f8d50626b70>, 'dhw': [32, 32, 32], 'k': 16, 'bottleneck': 4, 'compression': 2, 'first_layer': 32, 'down_structure': [2, 2, 2], 'output_size': 1, 'dropout_rate': None}\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            (None, 32, 32, 32, 1 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 32, 32, 32, 1 0           input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_136 (Conv3D)             (None, 32, 32, 32, 3 896         lambda_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 32, 32, 32, 3 128         conv3d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 32, 32, 32, 3 0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_137 (Conv3D)             (None, 32, 32, 32, 6 2048        activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 32, 32, 32, 6 256         conv3d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 32, 32, 32, 6 0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_138 (Conv3D)             (None, 32, 32, 32, 1 27664       activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_58 (Concatenate)    (None, 32, 32, 32, 4 0           conv3d_138[0][0]                 \n",
            "                                                                 conv3d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 32, 32, 32, 4 192         concatenate_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 32, 32, 32, 4 0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_139 (Conv3D)             (None, 32, 32, 32, 6 3072        activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 32, 32, 32, 6 256         conv3d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 32, 32, 32, 6 0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_140 (Conv3D)             (None, 32, 32, 32, 1 27664       activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_59 (Concatenate)    (None, 32, 32, 32, 6 0           conv3d_140[0][0]                 \n",
            "                                                                 concatenate_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 32, 32, 32, 6 256         concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 32, 32, 32, 6 0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_141 (Conv3D)             (None, 32, 32, 32, 3 2080        activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling3d_15 (AveragePo (None, 16, 16, 16, 3 0           conv3d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 16, 16, 16, 3 128         average_pooling3d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 16, 16, 16, 3 0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_142 (Conv3D)             (None, 16, 16, 16, 6 2048        activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 16, 16, 16, 6 256         conv3d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 16, 16, 16, 6 0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_143 (Conv3D)             (None, 16, 16, 16, 1 27664       activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_60 (Concatenate)    (None, 16, 16, 16, 4 0           conv3d_143[0][0]                 \n",
            "                                                                 average_pooling3d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 16, 16, 16, 4 192         concatenate_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 16, 16, 16, 4 0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_144 (Conv3D)             (None, 16, 16, 16, 6 3072        activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 16, 16, 16, 6 256         conv3d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 16, 16, 16, 6 0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_145 (Conv3D)             (None, 16, 16, 16, 1 27664       activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_61 (Concatenate)    (None, 16, 16, 16, 6 0           conv3d_145[0][0]                 \n",
            "                                                                 concatenate_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 16, 16, 16, 6 256         concatenate_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 16, 16, 16, 6 0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_146 (Conv3D)             (None, 16, 16, 16, 3 2080        activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling3d_16 (AveragePo (None, 8, 8, 8, 32)  0           conv3d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 8, 8, 8, 32)  128         average_pooling3d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 8, 8, 8, 32)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_147 (Conv3D)             (None, 8, 8, 8, 64)  2048        activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 8, 8, 8, 64)  256         conv3d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 8, 8, 8, 64)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_148 (Conv3D)             (None, 8, 8, 8, 16)  27664       activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_62 (Concatenate)    (None, 8, 8, 8, 48)  0           conv3d_148[0][0]                 \n",
            "                                                                 average_pooling3d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 8, 8, 8, 48)  192         concatenate_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 8, 8, 8, 48)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_149 (Conv3D)             (None, 8, 8, 8, 64)  3072        activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 8, 8, 8, 64)  256         conv3d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 8, 8, 8, 64)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_150 (Conv3D)             (None, 8, 8, 8, 16)  27664       activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_63 (Concatenate)    (None, 8, 8, 8, 64)  0           conv3d_150[0][0]                 \n",
            "                                                                 concatenate_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_15 (Conv3DTran (None, 16, 16, 16, 6 32832       concatenate_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 8, 8, 8, 64)  256         concatenate_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 16, 16, 16, 6 0           concatenate_61[0][0]             \n",
            "                                                                 conv3d_transpose_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 8, 8, 8, 64)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_transpose_16 (Conv3DTran (None, 32, 32, 32, 6 32832       add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d_8 (Glo (None, 64)           0           activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 32, 32, 32, 6 0           concatenate_59[0][0]             \n",
            "                                                                 conv3d_transpose_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "clf (Dense)                     (None, 1)            65          global_average_pooling3d_8[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "seg (Conv3D)                    (None, 32, 32, 32, 1 65          add_16[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 255,458\n",
            "Trainable params: 253,826\n",
            "Non-trainable params: 1,632\n",
            "__________________________________________________________________________________________________\n",
            "Size 117\n",
            "(117, 32, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mzSG9jKiYqH",
        "colab_type": "text"
      },
      "source": [
        "查看tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoMCqf1k84jK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "fac7b6e3-31aa-4695-de4f-4f72b815cb1f"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive')\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "LOG_DIR = '/content/tmp/test/logs'\n",
        "get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(LOG_DIR))\n",
        "\n",
        "#开启ngrok service，绑定port 6006(tensorboard)\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "\"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-02 13:48:59--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.7.241.210, 52.73.147.107, 3.234.122.223, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.7.241.210|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.7’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  16.3MB/s    in 0.8s    \n",
            "\n",
            "2020-01-02 13:49:00 (16.3 MB/s) - ‘ngrok-stable-linux-amd64.zip.7’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n",
            "https://85db9257.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
